{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwriting_to_Number.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+J05vYnmWiKUDjNce3kIx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sudoyolo/DS/blob/main/Handwriting_to_Number.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz0rkMbi13r5"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G85akue17qx"
      },
      "source": [
        "#import dataset\n",
        "#MNIST is the databse of handwritten digits\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "#Keras is a powerful and easy-to-use free open source Python library for developing and evaluating deep learning models.\n",
        "#Keras wraps the efficient numerical computation libraries Theano and TensorFlow and allows you to define and train neural network models in just a few lines of code."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNRA1iCz2Nex",
        "outputId": "5086b5b7-89f3-4a07-b074-fab299331123"
      },
      "source": [
        "#Divide the dataset into training and test dataset\n",
        "(x_train,y_train) ,(x_test,y_test) = mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPtH-zME2kuK",
        "outputId": "8b351a17-4bb4-4200-eb71-42576cc0fd82"
      },
      "source": [
        "#How data looks\n",
        "print(x_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
            "  175  26 166 255 247 127   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
            "  225 172 253 242 195  64   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
            "   93  82  82  56  39   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
            "   25   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
            "  150  27   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
            "  253 187   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
            "  253 249  64   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
            "  250 182   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
            "   78   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ue5CGtyc20di",
        "outputId": "1201470d-3e44-47b4-c0a9-66bd558de8be"
      },
      "source": [
        "#For Visualisation, use MatPlotLib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
        "plt.show()\n",
        "\n",
        "#CMAP parameter is a colormap instance or registered colormap name."
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-t7YjI73K-e",
        "outputId": "d108b03b-8b41-4c24-8adc-21ffe4c4ed1a"
      },
      "source": [
        "print(y_train[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejvNFUGK3Q8u"
      },
      "source": [
        "#Normalise\n",
        "\n",
        "#The x_train values are from 0-255 and hence the graph is dark.\n",
        "#We can normaise these values to make the values stay in between 0 and 1.\n",
        "\n",
        "'''\n",
        "Technical Definition:\n",
        "Normalise normalises a Numpy Array.\n",
        "\n",
        "Arguments:\n",
        "x: Numpy Array to normalise\n",
        "axis: axiis along which to normalise \n",
        "order: Normalization order (eg. order=2 for L2 Form)\n",
        "\n",
        "Returns:\n",
        "A normalised copy of that array.\n",
        "'''\n",
        "\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coqBWr7u3jBb",
        "outputId": "7de05d14-8db2-4156-c380-29c1026352b5"
      },
      "source": [
        "#How data looks after Normalisation\n",
        "print(x_train[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
            "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
            "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
            "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
            "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
            "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
            "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
            "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
            "  0.33153488 0.11664776 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.20500962\n",
            "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.01622378\n",
            "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
            "  0.04089933 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
            "  0.245396   0.05882702 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
            "  0.41390126 0.40743158 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.32161793\n",
            "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
            "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
            "  0.40899334 0.39653769 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.04117838 0.16813739\n",
            "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
            "  0.12760592 0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
            "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
            "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.37491383 0.56222061\n",
            "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
            "  0.17428513 0.01425695 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.92705966 0.82698729\n",
            "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "OWvaM25O3pjM",
        "outputId": "067fe711-1f70-4df4-cf59-8f94df3e84bf"
      },
      "source": [
        "#Visualisation after Normalisation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
        "plt.show()\n",
        "\n",
        "'''\n",
        "Now the graph is lighter yet the its clearly visible.\n",
        "Hence we can still train our models with smaller values in dataset resulting in faster processing of the model\n",
        "'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nNow the graph is lighter yet the its clearly visible.\\nHence we can still train our models with smaller values in dataset resulting in faster processing of the model\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp8iUDV13x_G"
      },
      "source": [
        " #Create model (https://datascience.stackexchange.com/questions/46124/what-do-compile-fit-and-predict-do-in-keras-sequential-models)\n",
        " model = tf.keras.models.Sequential()\n",
        "\n",
        " #We create sequential model because it is a feed-forward model. The values are going from left to right."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOIU-t-TM4a4"
      },
      "source": [
        "#Input into 1*784\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# To explain what Flatten does, open the link 'https://stackoverflow.com/questions/43237124/what-is-the-role-of-flatten-in-keras'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nk5yA7qNDLd"
      },
      "source": [
        "#Adding few layers\n",
        "model.add(tf.keras.layers.Dense(128 ,activation= tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128 ,activation= tf.nn.relu))\n",
        "model.add(tf.keras.layers.Dense(128 ,activation= tf.nn.relu))\n",
        "#Add Layer that adds a list of inputs. It takes as input a list of tensors, all of the same shape, and returns a single tensor (also of the same shape).\n",
        "#Dense adds a layer instance on top the layer stack. (https://stackoverflow.com/questions/43237124/what-is-the-role-of-flatten-in-keras). \n",
        "#The rectified linear activation function or ReLU for short is a piecewise linear function that will output the input directly if it is positive, otherwise, it will output zero."
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnkJhd6jNaZY"
      },
      "source": [
        "#Output Layer\n",
        "model.add(tf.keras.layers.Dense(10 ,activation= tf.nn.softmax))\n",
        "\n",
        "#Applies the Softmax function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range [0,1] and sum to 1.\n",
        "#We use 10 in Dense as we have only 10 possibilities in the output i.e. 0-9."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39sBfQdJNh0J"
      },
      "source": [
        "'''\n",
        "Let's first see what we need to do when we want to train a model.\n",
        "\n",
        "First, we want to decide a model architecture, this is the number of hidden layers and activation functions, etc. (compile)\n",
        "Secondly, we will want to train our model to get all the paramters to the correct value to map our inputs to our outputs. (fit)\n",
        "Lastly, we will want to use this model to do some feed-forward passes to predict novel inputs. (predict)\n",
        "'''\n",
        "model.compile( optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3lTXPzQOKvD",
        "outputId": "6a6ab348-9566-438f-ee02-6ccd478d01f2"
      },
      "source": [
        "model.fit(x_train, y_train, epochs = 3)\n",
        "#Epochs is number of times a model is to be run \n",
        "#Here, we run the model 3 times on our training set "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0566 - accuracy: 0.9820\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0389 - accuracy: 0.9870\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0332 - accuracy: 0.9892\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc97bf3bb50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-9miByLPDM8",
        "outputId": "747992d0-1154-4dc0-fab8-a78dc5c35344"
      },
      "source": [
        "val_loss, val_acc = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1091 - accuracy: 0.9709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNKvmGB_PS3Y"
      },
      "source": [
        "#Notice accuracy on train set is greater than that of test set."
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPFHvDMHUvuP"
      },
      "source": [
        "predictions = model.predict(x_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxcWw42fVw02",
        "outputId": "bdf18c57-e4d5-489b-979c-6dc53f23cf01"
      },
      "source": [
        "import numpy as np\n",
        "print(np.argmax(predictions[0]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_cBsFaJ0V42n",
        "outputId": "750435dd-1603-40b1-fc15-408286526320"
      },
      "source": [
        "plt.imshow(x_test[0] , cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zehi23zGWM4i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}